{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/krislars/R-uncertainty/blob/master/MonteCarloModeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHvCxXOdNtG6"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import numpy.random as npRand\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "from ipywidgets import interact\n",
    "from ipywidgets.widgets import FloatSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "glTrrResNtHK"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_ueJHiSNtHM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining some parameters:\n",
    "numVals = 1000\n",
    "diffABmin = 0.1\n",
    "diffABmax = 1.9\n",
    "numSteps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MultiDimensional linspace\n",
    "def ndlinspace(start, end, steps):\n",
    "    if (start.shape != end.shape):\n",
    "        print(\"Arrays must be same size\")\n",
    "        return\n",
    "    if (start.ndim == 1):\n",
    "        result = np.array(\n",
    "            [np.linspace(s, e, steps) for s,e in zip(start, end)]\n",
    "        )\n",
    "        return result\n",
    "    result = np.array(\n",
    "        [ndlinspace(s, e, steps) for s,e in zip(start, end)]\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p9jN6cgBO7nI"
   },
   "source": [
    "Data file format is intrinsic stellar H-K, sigma H-K, J-H, sigma J-H ... \n",
    "Davenport, J. R., Ivezic, Z., Becker, A. C., Ruan, J. J., Hunt-Walker, N. M., Covey, K. R., & Lewis, A. R. (2014, June). The SDSS-2MASS-WISE 10-dimensional stellar colour locus [Electronic version]. MNRAS, 440(4), 3430-3438.\n",
    "\n",
    "$$\n",
    "R = \\frac{A-B}{C-D}\n",
    "$$\n",
    "\n",
    "We will choose values such that the numerator is diffAB.  So, $A=(diffAB)+B$.  We also choose the value of R to be 1.6, so $C-D=(diffAB)/1.6$.  Therefore, $C = (diffAB)/1.6+D$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vYlpPR9aNtHP"
   },
   "outputs": [],
   "source": [
    "starData = np.loadtxt(\"https://raw.githubusercontent.com/krislars/R-uncertainty/master/Astro%20Lab%20Star%20Data.txt\", unpack=True)\n",
    "\n",
    "B, dB = starData[0], starData[1]\n",
    "D, dD = starData[2], starData[3]\n",
    "\n",
    "diffAB = np.linspace(diffABmin, diffABmax, numSteps)\n",
    "diffAB = np.transpose(ndlinspace(diffAB, diffAB, 50))\n",
    "\n",
    "B, dB = ndlinspace(B,B,numSteps), ndlinspace(dB,dB,numSteps)\n",
    "D, dD = ndlinspace(D,D,numSteps), ndlinspace(dD,dD,numSteps)\n",
    "\n",
    "A = diffAB + B\n",
    "C = diffAB/1.6 + D\n",
    "\n",
    "dA = dC = np.linspace(0.02, 0.02, 50)\n",
    "dA = dC = ndlinspace(dA, dA, numSteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5OFMufD1PQLo"
   },
   "source": [
    "This next line is propagation of error in an arithmetic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfbjC0rcNtHR"
   },
   "outputs": [],
   "source": [
    "#calculating theoretical dR\n",
    "dR = 1.6 *((dB**2 + dA**2)/diffAB**2 + (1.6/diffAB)**2 *(dD**2 + dC**2))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sPCdsLuhNtHU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8qSH1eItPYMs"
   },
   "source": [
    "This function takes a vector of values and a vector of associated uncertainties and returns an array of n = numVals samples selected randomly from a normal  probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6BBvp4zNtHX"
   },
   "outputs": [],
   "source": [
    "#choosing random data sets for each star type\n",
    "def ndNormalData(mean, sigma, numVals):\n",
    "    if (mean.shape != sigma.shape):\n",
    "        print(\"Arrays must be same size\")\n",
    "        return\n",
    "    if (mean.ndim == 1):\n",
    "        data = np.array(\n",
    "            [npRand.normal(m, s, numVals) for m, s in zip(mean, sigma)]\n",
    "        )\n",
    "        return data\n",
    "    \n",
    "    data = np.array(\n",
    "        [ndNormalData(m, s, numVals) for m, s in zip(mean, sigma)]\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42I5Fm77NtHZ"
   },
   "outputs": [],
   "source": [
    "B_vals = ndNormalData(B, dB, numVals)\n",
    "D_vals = ndNormalData(D, dD, numVals)\n",
    "A_vals = ndNormalData(A, dA, numVals)\n",
    "C_vals = ndNormalData(C, dC, numVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPy5nKcDNtHc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p5bnGFLtNtHf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rt9Fz0F0NtHi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100, 1000)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating the \"Monte Carlo\" values for R and dR\n",
    "R_vals = (A_vals - B_vals) / (C_vals - D_vals)\n",
    "R_vals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fvS2KtOMS29z"
   },
   "source": [
    "Now, we can test the distributions of R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBmPLyv7TV0Q"
   },
   "outputs": [],
   "source": [
    "R_mc = np.mean(R_vals, axis=2)\n",
    "dR_mc = np.std(R_vals, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "PZRywdePS1ol",
    "outputId": "a0064556-4624-49af-db0f-2650ea086bbc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3885f787020e414cade2d45957a06f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.55, description='diffABval', max=3.0, min=0.1, step=0.05), Output())â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_data(diffABval)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffABinit = (diffABmin + diffABmax) /2\n",
    "\n",
    "def findIndex(diffABval):\n",
    "    step = (diffABmax - diffABmin) / (numSteps-1)\n",
    "    result = (diffABval - diffABmin) / step\n",
    "    return int(result)\n",
    "\n",
    "def plot_data(diffABval):\n",
    "    x = np.arange(50)\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "    red_ax = plt.axes([0.1, 0.2, 0.8, 0.65])\n",
    "    \n",
    "    plt.ylim([1,3])\n",
    "    plt.title('Mean Reddening Across Star Types')\n",
    "    plt.errorbar(x, R_mc[x, findIndex(diffABval)], yerr=dR_mc[x, findIndex(diffABval)], fmt='ro')\n",
    "    plt.errorbar(x, np.linspace(1.6,1.6,50), fmt=\"b--\")\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_data, diffABval=FloatSlider(diffABinit, min=diffABmin, max=diffABmax, step=0.05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yc1d2lUnUOSx"
   },
   "source": [
    "Ideas going forward:\n",
    "* Calculate the uncertainty in the mean.\n",
    "* Try a weighted mean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defines binning of data to evenly space bins close to the mean\n",
    "#and group the outer bins together. This avoids an expected bincount of 0\n",
    "#for calculating chi-squared.\n",
    "def customBinning(data, numBins=20, dataWidth=8):\n",
    "    low = dataMin = min(data)\n",
    "    high = dataMax = max(data)\n",
    "    mean = np.mean(data)\n",
    "    stdev = np.std(data)\n",
    "    \n",
    "    if (dataMin < mean - dataWidth * stdev):\n",
    "        numBins = numBins - 1\n",
    "        low = mean - dataWidth * stdev\n",
    "    if (dataMax > mean + dataWidth * stdev):\n",
    "        numBins = numBins - 1\n",
    "        high = mean + dataWidth * stdev\n",
    "    \n",
    "    bins = np.linspace(low, high, numBins + 1)\n",
    "    \n",
    "    if (dataMin != low):\n",
    "        bins = np.concatenate((dataMin, bins), axis = None)\n",
    "    if (dataMax != high):\n",
    "        bins = np.concatenate((bins, dataMax), axis = None)\n",
    "    \n",
    "    return bins\n",
    "\n",
    "def ndHistogramCounts(Vals, numBins):\n",
    "    if (Vals.ndim == 1):\n",
    "        bins = customBinning(Vals, numBins)\n",
    "        counts, Bins = np.histogram(Vals, bins)\n",
    "        return counts\n",
    "    \n",
    "    results = np.stack(\n",
    "        ndHistogramCounts(vals, numBins) for vals in Vals\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def ndHistogramBins(Vals, numBins):\n",
    "    if (Vals.ndim == 1):\n",
    "        bins = customBinning(Vals, numBins)\n",
    "        #counts, Bins = np.histogram(Vals, bins)\n",
    "        return bins\n",
    "    \n",
    "    results = np.stack(\n",
    "        ndHistogramBins(vals, numBins) for vals in Vals\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def ndNormalCounts(mean, sigma, Bins):\n",
    "    if (mean.shape != sigma.shape):\n",
    "        print(\"Arrays must be same shape\")\n",
    "        return\n",
    "    \n",
    "    if (mean.ndim == 1):\n",
    "        counts = np.diff(np.stack(\n",
    "            stats.norm.cdf(bins, m, s) for bins, m, s in zip(Bins, mean, sigma)\n",
    "        ))\n",
    "        return counts\n",
    "    \n",
    "    counts = np.stack(\n",
    "        ndNormalCounts(m, s, bins) for m, s, bins in zip(mean, sigma, Bins)\n",
    "    )\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pOIKC-ICNtHo"
   },
   "outputs": [],
   "source": [
    "#Next I need to test \"Goodness of fit\"\n",
    "numBins = 20\n",
    "counts = ndHistogramCounts(R_vals, numBins)\n",
    "Bins = ndHistogramBins(R_vals, numBins)\n",
    "\n",
    "#calc expected with stats cdf and np.diff\n",
    "exp = ndNormalCounts(R_mc, dR_mc, Bins)\n",
    "\n",
    "#scale expected percentages by sample size\n",
    "exp = numVals * exp\n",
    "\n",
    "#Now calculate the Chi^2 values:\n",
    "chi2 = np.sum(( (counts - exp)**2 / exp), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-cTKn2LNtHm"
   },
   "outputs": [],
   "source": [
    "#Constraints in this case are the calculated mean, stdev, and total number of counts\n",
    "c = 3\n",
    "d = numBins - c\n",
    "red_chi2 = chi2/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "MonteCarloModeling.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
